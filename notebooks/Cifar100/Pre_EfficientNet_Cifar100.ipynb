{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "The87On52M1Q",
    "outputId": "b110b133-616f-4e7e-ffde-2f848ea96fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geffnet in /usr/local/lib/python3.6/dist-packages (0.9.7)\n",
      "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from geffnet) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from geffnet) (0.4.0a0+d31eafa)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->geffnet) (1.17.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->geffnet) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->geffnet) (6.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.6/dist-packages (0.1.18)\n",
      "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.6/dist-packages (from timm) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.4.0a0+d31eafa)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (6.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install geffnet\n",
    "!pip install torchsummary\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THFFFLtvqxwp"
   },
   "outputs": [],
   "source": [
    "import geffnet\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "from timm.optim.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Y_xGDxtxqyGp",
    "outputId": "7c43f23a-59a9-4dfd-df53-5eec207cc01a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "use_GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_GPU else \"cpu\")\n",
    "if use_GPU:\n",
    "    torch.cuda.manual_seed(0)\n",
    "    print('Device: ' + str(device))\n",
    "    print('GPU: ' + str(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"Using GPU: {}\".format(use_GPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yrPQf4Sq0sI"
   },
   "outputs": [],
   "source": [
    "def ImageProcessing():\n",
    "    transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(), transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "\n",
    "    train_dat = datasets.CIFAR100(root=sys.path[0] + \"/data/CIFAR100\", train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dat, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    test_dat = datasets.CIFAR100(root=sys.path[0] + '/data/CIFAR100', train=False, download=True, transform=transform)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dat, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9i2kRq9Rq5gn"
   },
   "outputs": [],
   "source": [
    "def training(model, train_loader, optimizer, criterion, epoch):\n",
    "    training_loss = 0\n",
    "    model.train()\n",
    "    bi = 200\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        if batch_idx % bi == bi-1:  # print every 2000 mini-batches\n",
    "            print('[epoch: %d, batch: %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, training_loss / bi))\n",
    "            training_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7USv_wJ1q50m"
   },
   "outputs": [],
   "source": [
    "def testing(model, test_loader, criterion):\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for inputs, targets in test_loader:\n",
    "          \n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            test_loss += criterion(outputs, targets).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            total += 1\n",
    "\n",
    "    print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {:.4f}\\n\".format(test_loss / total,\n",
    "                                                                        correct / len(test_loader.dataset)))\n",
    "    return test_loss / total, correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkhUTENfq_D1"
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLK9bp07q_Xd"
   },
   "outputs": [],
   "source": [
    "def fine_tuning(model):\n",
    "\n",
    "    epochs = 40\n",
    "\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # optimizer = torch.optim.RMSprop(params_to_update, lr = 0.0001, weight_decay =1e-5)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.99, weight_decay=1e-5)\n",
    "\n",
    "    reduce_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=1)\n",
    "\n",
    "    train_loader, test_loader = ImageProcessing()\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print_learning_rate(optimizer, epoch+1)\n",
    "\n",
    "        training(model, train_loader, optimizer, criterion, epoch)\n",
    "\n",
    "        loss, acc = testing(model, test_loader, criterion)\n",
    "\n",
    "        test_loss.append(loss)\n",
    "\n",
    "        test_acc.append(acc)\n",
    "\n",
    "        reduce_lr.step(loss)\n",
    "\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "    ax1.plot(list(range(1,epochs+1)), test_acc)\n",
    "    ax1.set(xlabel='epochs', ylabel='test accuracy')\n",
    "    ax2.plot(list(range(1,epochs+1)), test_loss)\n",
    "    ax2.set(xlabel='epochs', ylabel='test loss')\n",
    "    fig.tight_layout(pad=4.0)\n",
    "    ax2.set_xticks(np.arange(1, epochs+1, step=1))\n",
    "    ax1.set_xticks(np.arange(1, epochs+1, step=1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J460uqKKrG4p"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(lr, optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 0.97 every 2.4 epochs\"\"\"\n",
    "    lr = lr * (0.97 ** (epoch // 2))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def print_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"Epoch: [{}] Current learning rate (lr) = {}\".format(\n",
    "                                                    epoch, param_group['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZhSJGnMrDsU"
   },
   "outputs": [],
   "source": [
    "def main(md):\n",
    "\n",
    "    # classes = ('plane', 'car', 'bird', 'cat',\n",
    "    #            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # classes = (\n",
    "    # 'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    # 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    # 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    # 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    # 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    # 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    # 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    # 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    # 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    # 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    # 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    # 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    # 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    # 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    # 'worm')\n",
    "\n",
    "    train_loader, test_loader = ImageProcessing()\n",
    "    \n",
    "    # print(len(classes))\n",
    "    # imageshow(train_loader, classes)\n",
    "\n",
    "    momentum = 0.9\n",
    "    epochs = 20\n",
    "    decay = 1e-5\n",
    "    lr = 0.001\n",
    "\n",
    "    model = md.to(device)\n",
    "\n",
    "    summary(model,(3,224,224),batch_size=10)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
    "    \n",
    "    optimizer = optim.RAdam(model.parameters(), lr=lr, weight_decay = decay)\n",
    "\n",
    "    # reduce_lr = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "    reduce_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print_learning_rate(optimizer,epoch+1)\n",
    "        training(model, train_loader, optimizer, criterion, epoch)\n",
    "        loss,_ = testing(model, test_loader, criterion)\n",
    "        # adjust_learning_rate(lr, optimizer,epoch+1)\n",
    "        reduce_lr.step(loss)\n",
    "\n",
    "    # PATH = './cifar_net.pth'\n",
    "    # torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "fe4738ef0bfe46ee8677a43ccf013b7f",
      "16e844c36acb49968c4658b84c6791c6",
      "8864d4f7405341a6be208d132866e659",
      "e92b75192404427180b16ac807e47d8b",
      "56c6650711ee4f95adcfd244d0a9d165",
      "6d46c0f9493f4d7289f38e6a8ed158ed",
      "01f474c3e87b4742a43aa43bd306cb31",
      "c6e3d437239549b69f47e2e45b0f2442"
     ]
    },
    "colab_type": "code",
    "id": "ktT9bF7krEES",
    "outputId": "89dff731-fdfe-4d8e-cdbd-4a93b9887fc9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_es', 'fbnetc_100', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mnasnet_a1', 'mnasnet_b1', 'mobilenetv3_rw', 'spnasnet_100', 'tf_efficientnet_b0', 'tf_efficientnet_b0_ap', 'tf_efficientnet_b0_ns', 'tf_efficientnet_b1', 'tf_efficientnet_b1_ap', 'tf_efficientnet_b1_ns', 'tf_efficientnet_b2', 'tf_efficientnet_b2_ap', 'tf_efficientnet_b2_ns', 'tf_efficientnet_b3', 'tf_efficientnet_b3_ap', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b4', 'tf_efficientnet_b4_ap', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b5', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b5_ns', 'tf_efficientnet_b6', 'tf_efficientnet_b6_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7', 'tf_efficientnet_b7_ap', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2_ns', 'tf_efficientnet_l2_ns_475', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: [1] Current learning rate (lr) = 0.001\n",
      "[epoch: 1, batch:   200] loss: 4.041\n",
      "[epoch: 1, batch:   400] loss: 1.765\n",
      "[epoch: 1, batch:   600] loss: 1.292\n",
      "[epoch: 1, batch:   800] loss: 1.132\n",
      "[epoch: 1, batch:  1000] loss: 1.025\n",
      "[epoch: 1, batch:  1200] loss: 1.016\n",
      "[epoch: 1, batch:  1400] loss: 0.924\n",
      "\n",
      "Test set: Average loss: 0.7664, Accuracy: 0.7659\n",
      "\n",
      "Epoch: [2] Current learning rate (lr) = 0.001\n",
      "[epoch: 2, batch:   200] loss: 0.824\n",
      "[epoch: 2, batch:   400] loss: 0.668\n",
      "[epoch: 2, batch:   600] loss: 0.590\n",
      "[epoch: 2, batch:   800] loss: 0.509\n",
      "[epoch: 2, batch:  1000] loss: 0.502\n",
      "[epoch: 2, batch:  1200] loss: 0.473\n",
      "[epoch: 2, batch:  1400] loss: 0.462\n",
      "\n",
      "Test set: Average loss: 0.7819, Accuracy: 0.7717\n",
      "\n",
      "Epoch: [3] Current learning rate (lr) = 0.001\n",
      "[epoch: 3, batch:   200] loss: 0.413\n",
      "[epoch: 3, batch:   400] loss: 0.337\n",
      "[epoch: 3, batch:   600] loss: 0.301\n",
      "[epoch: 3, batch:   800] loss: 0.269\n",
      "[epoch: 3, batch:  1000] loss: 0.285\n",
      "[epoch: 3, batch:  1200] loss: 0.273\n",
      "[epoch: 3, batch:  1400] loss: 0.273\n",
      "\n",
      "Test set: Average loss: 0.8184, Accuracy: 0.7795\n",
      "\n",
      "Epoch: [4] Current learning rate (lr) = 0.0005\n",
      "[epoch: 4, batch:   200] loss: 0.224\n",
      "[epoch: 4, batch:   400] loss: 0.164\n",
      "[epoch: 4, batch:   600] loss: 0.148\n",
      "[epoch: 4, batch:   800] loss: 0.114\n",
      "[epoch: 4, batch:  1000] loss: 0.109\n",
      "[epoch: 4, batch:  1200] loss: 0.089\n",
      "[epoch: 4, batch:  1400] loss: 0.070\n",
      "\n",
      "Test set: Average loss: 0.6435, Accuracy: 0.8339\n",
      "\n",
      "Epoch: [5] Current learning rate (lr) = 0.0005\n",
      "[epoch: 5, batch:   200] loss: 0.062\n",
      "[epoch: 5, batch:   400] loss: 0.044\n",
      "[epoch: 5, batch:   600] loss: 0.043\n",
      "[epoch: 5, batch:   800] loss: 0.033\n",
      "[epoch: 5, batch:  1000] loss: 0.028\n",
      "[epoch: 5, batch:  1200] loss: 0.024\n",
      "[epoch: 5, batch:  1400] loss: 0.019\n",
      "[epoch: 6, batch:  1000] loss: 0.009\n",
      "[epoch: 6, batch:  1200] loss: 0.009\n",
      "[epoch: 6, batch:  1400] loss: 0.007\n",
      "\n",
      "Test set: Average loss: 0.6623, Accuracy: 0.8437\n",
      "\n",
      "Epoch: [7] Current learning rate (lr) = 0.0005\n",
      "[epoch: 7, batch:   200] loss: 0.007\n",
      "[epoch: 7, batch:   400] loss: 0.006\n",
      "[epoch: 7, batch:   600] loss: 0.006\n",
      "[epoch: 7, batch:   800] loss: 0.005\n",
      "[epoch: 7, batch:  1000] loss: 0.004\n",
      "[epoch: 7, batch:  1200] loss: 0.005\n",
      "[epoch: 7, batch:  1400] loss: 0.004\n",
      "\n",
      "Test set: Average loss: 0.6782, Accuracy: 0.8434\n",
      "\n",
      "Epoch: [8] Current learning rate (lr) = 0.00025\n",
      "[epoch: 8, batch:   200] loss: 0.004\n",
      "[epoch: 8, batch:   400] loss: 0.004\n",
      "[epoch: 8, batch:   600] loss: 0.004\n",
      "[epoch: 8, batch:   800] loss: 0.003\n",
      "[epoch: 8, batch:  1000] loss: 0.003\n",
      "[epoch: 8, batch:  1200] loss: 0.003\n",
      "[epoch: 8, batch:  1400] loss: 0.003\n",
      "\n",
      "Test set: Average loss: 0.6824, Accuracy: 0.8458\n",
      "\n",
      "Epoch: [9] Current learning rate (lr) = 0.00025\n",
      "[epoch: 9, batch:   200] loss: 0.003\n",
      "[epoch: 9, batch:   400] loss: 0.003\n",
      "[epoch: 9, batch:   600] loss: 0.003\n",
      "[epoch: 9, batch:   800] loss: 0.003\n",
      "[epoch: 9, batch:  1000] loss: 0.003\n",
      "[epoch: 9, batch:  1200] loss: 0.002\n",
      "[epoch: 9, batch:  1400] loss: 0.003\n",
      "\n",
      "Test set: Average loss: 0.6889, Accuracy: 0.8454\n",
      "\n",
      "Epoch: [10] Current learning rate (lr) = 0.000125\n",
      "[epoch: 10, batch:   200] loss: 0.003\n",
      "[epoch: 10, batch:   400] loss: 0.003\n",
      "[epoch: 10, batch:   600] loss: 0.003\n",
      "[epoch: 10, batch:   800] loss: 0.003\n",
      "[epoch: 10, batch:  1000] loss: 0.002\n",
      "[epoch: 10, batch:  1200] loss: 0.002\n",
      "[epoch: 10, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6918, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [11] Current learning rate (lr) = 0.000125\n",
      "[epoch: 11, batch:   200] loss: 0.003\n",
      "[epoch: 11, batch:   400] loss: 0.002\n",
      "[epoch: 11, batch:   600] loss: 0.003\n",
      "[epoch: 11, batch:   800] loss: 0.002\n",
      "[epoch: 11, batch:  1000] loss: 0.002\n",
      "[epoch: 11, batch:  1200] loss: 0.002\n",
      "[epoch: 11, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6945, Accuracy: 0.8446\n",
      "\n",
      "Epoch: [12] Current learning rate (lr) = 6.25e-05\n",
      "[epoch: 12, batch:   200] loss: 0.002\n",
      "[epoch: 12, batch:   400] loss: 0.002\n",
      "[epoch: 12, batch:   600] loss: 0.002\n",
      "[epoch: 12, batch:   800] loss: 0.002\n",
      "[epoch: 12, batch:  1000] loss: 0.002\n",
      "[epoch: 12, batch:  1200] loss: 0.002\n",
      "[epoch: 12, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6958, Accuracy: 0.8442\n",
      "\n",
      "Epoch: [13] Current learning rate (lr) = 6.25e-05\n",
      "[epoch: 13, batch:   200] loss: 0.002\n",
      "[epoch: 13, batch:   400] loss: 0.002\n",
      "[epoch: 13, batch:   600] loss: 0.002\n",
      "[epoch: 13, batch:   800] loss: 0.002\n",
      "[epoch: 13, batch:  1000] loss: 0.002\n",
      "[epoch: 13, batch:  1200] loss: 0.002\n",
      "[epoch: 13, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6971, Accuracy: 0.8443\n",
      "\n",
      "Epoch: [14] Current learning rate (lr) = 3.125e-05\n",
      "[epoch: 14, batch:   200] loss: 0.002\n",
      "[epoch: 14, batch:   400] loss: 0.002\n",
      "[epoch: 14, batch:   600] loss: 0.002\n",
      "[epoch: 14, batch:   800] loss: 0.002\n",
      "[epoch: 14, batch:  1000] loss: 0.002\n",
      "[epoch: 14, batch:  1200] loss: 0.002\n",
      "[epoch: 14, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6978, Accuracy: 0.8446\n",
      "\n",
      "Epoch: [15] Current learning rate (lr) = 3.125e-05\n",
      "[epoch: 15, batch:   200] loss: 0.002\n",
      "[epoch: 15, batch:   400] loss: 0.002\n",
      "[epoch: 15, batch:   600] loss: 0.002\n",
      "[epoch: 15, batch:   800] loss: 0.002\n",
      "[epoch: 15, batch:  1000] loss: 0.002\n",
      "[epoch: 15, batch:  1200] loss: 0.002\n",
      "[epoch: 15, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6984, Accuracy: 0.8448\n",
      "\n",
      "Epoch: [16] Current learning rate (lr) = 1.5625e-05\n",
      "[epoch: 16, batch:   200] loss: 0.002\n",
      "[epoch: 16, batch:   400] loss: 0.002\n",
      "[epoch: 16, batch:   600] loss: 0.002\n",
      "[epoch: 16, batch:   800] loss: 0.002\n",
      "[epoch: 16, batch:  1000] loss: 0.002\n",
      "[epoch: 16, batch:  1200] loss: 0.002\n",
      "[epoch: 16, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6987, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [17] Current learning rate (lr) = 1.5625e-05\n",
      "[epoch: 17, batch:   200] loss: 0.002\n",
      "[epoch: 17, batch:   400] loss: 0.002\n",
      "[epoch: 17, batch:   600] loss: 0.002\n",
      "[epoch: 17, batch:   800] loss: 0.002\n",
      "[epoch: 17, batch:  1000] loss: 0.002\n",
      "[epoch: 17, batch:  1200] loss: 0.002\n",
      "[epoch: 17, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6991, Accuracy: 0.8450\n",
      "\n",
      "Epoch: [18] Current learning rate (lr) = 7.8125e-06\n",
      "[epoch: 18, batch:   200] loss: 0.002\n",
      "[epoch: 18, batch:   400] loss: 0.002\n",
      "[epoch: 18, batch:   600] loss: 0.002\n",
      "[epoch: 18, batch:   800] loss: 0.002\n",
      "[epoch: 18, batch:  1000] loss: 0.002\n",
      "[epoch: 18, batch:  1200] loss: 0.002\n",
      "[epoch: 18, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6992, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [19] Current learning rate (lr) = 7.8125e-06\n",
      "[epoch: 19, batch:   200] loss: 0.002\n",
      "[epoch: 19, batch:   400] loss: 0.002\n",
      "[epoch: 19, batch:   600] loss: 0.002\n",
      "[epoch: 19, batch:   800] loss: 0.002\n",
      "[epoch: 19, batch:  1000] loss: 0.002\n",
      "[epoch: 19, batch:  1200] loss: 0.002\n",
      "[epoch: 19, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6993, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [20] Current learning rate (lr) = 3.90625e-06\n",
      "[epoch: 20, batch:   200] loss: 0.002\n",
      "[epoch: 20, batch:   400] loss: 0.002\n",
      "[epoch: 20, batch:   600] loss: 0.002\n",
      "[epoch: 20, batch:   800] loss: 0.002\n",
      "[epoch: 20, batch:  1000] loss: 0.002\n",
      "[epoch: 20, batch:  1200] loss: 0.002\n",
      "[epoch: 20, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6994, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [21] Current learning rate (lr) = 3.90625e-06\n",
      "[epoch: 21, batch:   200] loss: 0.002\n",
      "[epoch: 21, batch:   400] loss: 0.002\n",
      "[epoch: 21, batch:   600] loss: 0.002\n",
      "[epoch: 21, batch:   800] loss: 0.002\n",
      "[epoch: 21, batch:  1000] loss: 0.002\n",
      "[epoch: 21, batch:  1200] loss: 0.002\n",
      "[epoch: 21, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6994, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [22] Current learning rate (lr) = 1.953125e-06\n",
      "[epoch: 22, batch:   200] loss: 0.002\n",
      "[epoch: 22, batch:   400] loss: 0.002\n",
      "[epoch: 22, batch:   600] loss: 0.002\n",
      "[epoch: 22, batch:   800] loss: 0.002\n",
      "[epoch: 22, batch:  1000] loss: 0.002\n",
      "[epoch: 22, batch:  1200] loss: 0.002\n",
      "[epoch: 22, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [23] Current learning rate (lr) = 1.953125e-06\n",
      "[epoch: 23, batch:   200] loss: 0.002\n",
      "[epoch: 23, batch:   400] loss: 0.002\n",
      "[epoch: 23, batch:   600] loss: 0.002\n",
      "[epoch: 23, batch:   800] loss: 0.002\n",
      "[epoch: 23, batch:  1000] loss: 0.002\n",
      "[epoch: 23, batch:  1200] loss: 0.002\n",
      "[epoch: 23, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [24] Current learning rate (lr) = 9.765625e-07\n",
      "[epoch: 24, batch:   200] loss: 0.002\n",
      "[epoch: 24, batch:   400] loss: 0.002\n",
      "[epoch: 24, batch:   600] loss: 0.002\n",
      "[epoch: 24, batch:   800] loss: 0.002\n",
      "[epoch: 24, batch:  1000] loss: 0.002\n",
      "[epoch: 24, batch:  1200] loss: 0.002\n",
      "[epoch: 24, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [25] Current learning rate (lr) = 9.765625e-07\n",
      "[epoch: 25, batch:   200] loss: 0.002\n",
      "[epoch: 25, batch:   400] loss: 0.002\n",
      "[epoch: 25, batch:   600] loss: 0.002\n",
      "[epoch: 25, batch:   800] loss: 0.002\n",
      "[epoch: 25, batch:  1000] loss: 0.002\n",
      "[epoch: 25, batch:  1200] loss: 0.002\n",
      "[epoch: 25, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [26] Current learning rate (lr) = 4.8828125e-07\n",
      "[epoch: 26, batch:   200] loss: 0.002\n",
      "[epoch: 26, batch:   400] loss: 0.002\n",
      "[epoch: 26, batch:   600] loss: 0.002\n",
      "[epoch: 26, batch:   800] loss: 0.002\n",
      "[epoch: 26, batch:  1000] loss: 0.002\n",
      "[epoch: 26, batch:  1200] loss: 0.002\n",
      "[epoch: 26, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [27] Current learning rate (lr) = 4.8828125e-07\n",
      "[epoch: 27, batch:   200] loss: 0.002\n",
      "[epoch: 27, batch:   400] loss: 0.002\n",
      "[epoch: 27, batch:   600] loss: 0.002\n",
      "[epoch: 27, batch:   800] loss: 0.002\n",
      "[epoch: 27, batch:  1000] loss: 0.002\n",
      "[epoch: 27, batch:  1200] loss: 0.002\n",
      "[epoch: 27, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [28] Current learning rate (lr) = 2.44140625e-07\n",
      "[epoch: 28, batch:   200] loss: 0.002\n",
      "[epoch: 28, batch:   400] loss: 0.002\n",
      "[epoch: 28, batch:   600] loss: 0.002\n",
      "[epoch: 28, batch:   800] loss: 0.002\n",
      "[epoch: 28, batch:  1000] loss: 0.002\n",
      "[epoch: 28, batch:  1200] loss: 0.002\n",
      "[epoch: 28, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [29] Current learning rate (lr) = 2.44140625e-07\n",
      "[epoch: 29, batch:   200] loss: 0.002\n",
      "[epoch: 29, batch:   400] loss: 0.002\n",
      "[epoch: 29, batch:   600] loss: 0.002\n",
      "[epoch: 29, batch:   800] loss: 0.002\n",
      "[epoch: 29, batch:  1000] loss: 0.002\n",
      "[epoch: 29, batch:  1200] loss: 0.002\n",
      "[epoch: 29, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [30] Current learning rate (lr) = 1.220703125e-07\n",
      "[epoch: 30, batch:   200] loss: 0.002\n",
      "[epoch: 30, batch:   400] loss: 0.002\n",
      "[epoch: 30, batch:   600] loss: 0.002\n",
      "[epoch: 30, batch:   800] loss: 0.002\n",
      "[epoch: 30, batch:  1000] loss: 0.002\n",
      "[epoch: 30, batch:  1200] loss: 0.002\n",
      "[epoch: 30, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [31] Current learning rate (lr) = 1.220703125e-07\n",
      "[epoch: 31, batch:   200] loss: 0.002\n",
      "[epoch: 31, batch:   400] loss: 0.002\n",
      "[epoch: 31, batch:   600] loss: 0.002\n",
      "[epoch: 31, batch:   800] loss: 0.002\n",
      "[epoch: 31, batch:  1000] loss: 0.002\n",
      "[epoch: 31, batch:  1200] loss: 0.002\n",
      "[epoch: 31, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [32] Current learning rate (lr) = 6.103515625e-08\n",
      "[epoch: 32, batch:   200] loss: 0.002\n",
      "[epoch: 32, batch:   400] loss: 0.002\n",
      "[epoch: 32, batch:   600] loss: 0.002\n",
      "[epoch: 32, batch:   800] loss: 0.002\n",
      "[epoch: 32, batch:  1000] loss: 0.002\n",
      "[epoch: 32, batch:  1200] loss: 0.002\n",
      "[epoch: 32, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [33] Current learning rate (lr) = 6.103515625e-08\n",
      "[epoch: 33, batch:   200] loss: 0.002\n",
      "[epoch: 33, batch:   400] loss: 0.002\n",
      "[epoch: 33, batch:   600] loss: 0.002\n",
      "[epoch: 33, batch:   800] loss: 0.002\n",
      "[epoch: 33, batch:  1000] loss: 0.002\n",
      "[epoch: 33, batch:  1200] loss: 0.002\n",
      "[epoch: 33, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [34] Current learning rate (lr) = 3.0517578125e-08\n",
      "[epoch: 34, batch:   200] loss: 0.002\n",
      "[epoch: 34, batch:   400] loss: 0.002\n",
      "[epoch: 34, batch:   600] loss: 0.002\n",
      "[epoch: 34, batch:   800] loss: 0.002\n",
      "[epoch: 34, batch:  1000] loss: 0.002\n",
      "[epoch: 34, batch:  1200] loss: 0.002\n",
      "[epoch: 34, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [35] Current learning rate (lr) = 3.0517578125e-08\n",
      "[epoch: 35, batch:   200] loss: 0.002\n",
      "[epoch: 35, batch:   400] loss: 0.002\n",
      "[epoch: 35, batch:   600] loss: 0.002\n",
      "[epoch: 35, batch:   800] loss: 0.002\n",
      "[epoch: 35, batch:  1000] loss: 0.002\n",
      "[epoch: 35, batch:  1200] loss: 0.002\n",
      "[epoch: 35, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [36] Current learning rate (lr) = 1.52587890625e-08\n",
      "[epoch: 36, batch:   200] loss: 0.002\n",
      "[epoch: 36, batch:   400] loss: 0.002\n",
      "[epoch: 36, batch:   600] loss: 0.002\n",
      "[epoch: 36, batch:   800] loss: 0.002\n",
      "[epoch: 36, batch:  1000] loss: 0.002\n",
      "[epoch: 36, batch:  1200] loss: 0.002\n",
      "[epoch: 36, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [37] Current learning rate (lr) = 1.52587890625e-08\n",
      "[epoch: 37, batch:   200] loss: 0.002\n",
      "[epoch: 37, batch:   400] loss: 0.002\n",
      "[epoch: 37, batch:   600] loss: 0.002\n",
      "[epoch: 37, batch:   800] loss: 0.002\n",
      "[epoch: 37, batch:  1000] loss: 0.002\n",
      "[epoch: 37, batch:  1200] loss: 0.002\n",
      "[epoch: 37, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [38] Current learning rate (lr) = 1.52587890625e-08\n",
      "[epoch: 38, batch:   200] loss: 0.002\n",
      "[epoch: 38, batch:   400] loss: 0.002\n",
      "[epoch: 38, batch:   600] loss: 0.002\n",
      "[epoch: 38, batch:   800] loss: 0.002\n",
      "[epoch: 38, batch:  1000] loss: 0.002\n",
      "[epoch: 38, batch:  1200] loss: 0.002\n",
      "[epoch: 38, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [39] Current learning rate (lr) = 1.52587890625e-08\n",
      "[epoch: 39, batch:   200] loss: 0.002\n",
      "[epoch: 39, batch:   400] loss: 0.002\n",
      "[epoch: 39, batch:   600] loss: 0.002\n",
      "[epoch: 39, batch:   800] loss: 0.002\n",
      "[epoch: 39, batch:  1000] loss: 0.002\n",
      "[epoch: 39, batch:  1200] loss: 0.002\n",
      "[epoch: 39, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n",
      "Epoch: [40] Current learning rate (lr) = 1.52587890625e-08\n",
      "[epoch: 40, batch:   200] loss: 0.002\n",
      "[epoch: 40, batch:   400] loss: 0.002\n",
      "[epoch: 40, batch:   600] loss: 0.002\n",
      "[epoch: 40, batch:   800] loss: 0.002\n",
      "[epoch: 40, batch:  1000] loss: 0.002\n",
      "[epoch: 40, batch:  1200] loss: 0.002\n",
      "[epoch: 40, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 0.8449\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GenEfficientNet(\n",
       "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): SwishJit()\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): SwishJit()\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Linear(in_features=1280, out_features=100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.hub.list('rwightman/gen-efficientnet-pytorch'))\n",
    "\n",
    "md = geffnet.create_model('efficientnet_b0',pretrained=True)\n",
    "\n",
    "md.classifier = torch.nn.Linear(1280,100,bias=False)\n",
    "\n",
    "fine_tuning(md)\n",
    "\n",
    "# main(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiiBu36AsHL1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "EfficientNet_Cifar100.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01f474c3e87b4742a43aa43bd306cb31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16e844c36acb49968c4658b84c6791c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56c6650711ee4f95adcfd244d0a9d165": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6d46c0f9493f4d7289f38e6a8ed158ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8864d4f7405341a6be208d132866e659": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": " 36%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d46c0f9493f4d7289f38e6a8ed158ed",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56c6650711ee4f95adcfd244d0a9d165",
      "value": 1
     }
    },
    "c6e3d437239549b69f47e2e45b0f2442": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e92b75192404427180b16ac807e47d8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6e3d437239549b69f47e2e45b0f2442",
      "placeholder": "",
      "style": "IPY_MODEL_01f474c3e87b4742a43aa43bd306cb31",
      "value": " 61595648/169001437 [00:05&lt;00:06, 16510835.36it/s]"
     }
    },
    "fe4738ef0bfe46ee8677a43ccf013b7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8864d4f7405341a6be208d132866e659",
       "IPY_MODEL_e92b75192404427180b16ac807e47d8b"
      ],
      "layout": "IPY_MODEL_16e844c36acb49968c4658b84c6791c6"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
