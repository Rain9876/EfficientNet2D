{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5108,
     "status": "ok",
     "timestamp": 1586102803551,
     "user": {
      "displayName": "Yurun SONG",
      "photoUrl": "",
      "userId": "00512124433136381755"
     },
     "user_tz": -60
    },
    "id": "DSc3v42uVfGQ",
    "outputId": "b4939073-e288-45cc-e25d-7f6d85114192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e9/dfee5381ae8e7862d8565cfc9ad7056dccbf2eefa214256da6b2fd878702/timm-0.1.18-py3-none-any.whl (158kB)\n",
      "\r",
      "\u001b[K     |██                              | 10kB 25.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 20kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 30kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 40kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 51kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 61kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 71kB 3.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 81kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 92kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 102kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 112kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 122kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 133kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 143kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 153kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 163kB 3.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.5.0)\n",
      "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.6/dist-packages (from timm) (1.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (1.18.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (7.0.0)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.1.18\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3bXOFnLmsYL"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "import math\n",
    "from torchsummary import summary\n",
    "from timm.models.layers.create_conv2d import create_conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8242,
     "status": "ok",
     "timestamp": 1586102806700,
     "user": {
      "displayName": "Yurun SONG",
      "photoUrl": "",
      "userId": "00512124433136381755"
     },
     "user_tz": -60
    },
    "id": "7rxjlxFHnBDU",
    "outputId": "d66e42de-28e1-4b91-fa58-f8832930e262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "use_GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_GPU else \"cpu\")\n",
    "if use_GPU:\n",
    "    torch.cuda.manual_seed(0)\n",
    "print(\"Using GPU: {}\".format(use_GPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7CEnHV62mtNx"
   },
   "outputs": [],
   "source": [
    "blockArgs = namedtuple(\"Block_args\",\n",
    "                       [\"kernel_size\", \"num_repeat\", \"input_channels\", \"output_channels\", \"expand_ratio\",\n",
    "                        \"id_skip\", \"se_ratio\", \"strides\"])\n",
    "\n",
    "blockArgs.__new__.__defaults__ = (None,) * len(blockArgs._fields)\n",
    "\n",
    "BLOCKS_ARGS = [\n",
    "    blockArgs(kernel_size=3, num_repeat=1, input_channels=32, output_channels=16,\n",
    "              expand_ratio=1, id_skip=True, strides=1, se_ratio=0.25),\n",
    "    blockArgs(kernel_size=3, num_repeat=2, input_channels=16, output_channels=24,\n",
    "              expand_ratio=6, id_skip=True, strides=2, se_ratio=0.25),\n",
    "    blockArgs(kernel_size=5, num_repeat=2, input_channels=24, output_channels=40,\n",
    "              expand_ratio=6, id_skip=True, strides=2, se_ratio=0.25),\n",
    "    blockArgs(kernel_size=3, num_repeat=3, input_channels=40, output_channels=80,\n",
    "              expand_ratio=6, id_skip=True, strides=2, se_ratio=0.25),\n",
    "    blockArgs(kernel_size=5, num_repeat=3, input_channels=80, output_channels=112,\n",
    "              expand_ratio=6, id_skip=True, strides=1, se_ratio=0.25),\n",
    "    blockArgs(kernel_size=5, num_repeat=4, input_channels=112, output_channels=192,\n",
    "              expand_ratio=6, id_skip=True, strides=2, se_ratio=0.25),\n",
    "    blockArgs(kernel_size=3, num_repeat=1, input_channels=192, output_channels=320,\n",
    "              expand_ratio=6, id_skip=True, strides=1, se_ratio=0.25)\n",
    "]\n",
    "\n",
    "\n",
    "# Construct the swish activation function  to replace the ReLU6\n",
    "# Swish f(x) = x * sigmoid(x) works better than ReLu in deeper model\n",
    "# https://arxiv.org/abs/1710.05941\n",
    "\n",
    "# A formula differentiate the Swish operation\n",
    "class Swish(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_tensors[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        return grad_output * (sigmoid_i + i * sigmoid_i * (1 - sigmoid_i))\n",
    "\n",
    "# MemoryEfficientSwish saves more memories than just using swish\n",
    "# Save the input for back propagation, save more space for computing derivative\n",
    "# https://medium.com/the-artificial-impostor/more-memory-efficient-swish-activation-function-e07c22c12a76\n",
    "class EfficientSwish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        # S = Swish.apply\n",
    "        # return S(input)\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "\n",
    "# The width of Network / the number of neurons of each CNN layer multiples width_coeff\n",
    "# The number of neuron is the number of filter.\n",
    "# Return the the the number of filter after width expansion.\n",
    "def round_filters(filters, width_coeff, depth_divisor):\n",
    "    filters *= width_coeff\n",
    "    new_filters = int(\n",
    "        filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
    "    new_filters = max(depth_divisor, new_filters)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_filters < 0.9 * filters:\n",
    "        new_filters += depth_divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "# The depth of Network / the repeated times of each block multiples depth_coeff\n",
    "# For example, the block repeat 3 times, therefore, the real depth for the block is multiplied by depth coeff\n",
    "def round_repeated(repeats, depth_coeff):\n",
    "    return int(math.ceil(depth_coeff * repeats))\n",
    "\n",
    "\n",
    "# DropConnect works similar to Dropout, except that drop connect disable individual weights (i.e., set them to zero),\n",
    "# instead of nodes\n",
    "def drop_connect(inputs, drop_connect_rate):\n",
    "    batch_size = list(inputs.size())[0]\n",
    "    keep_prob = 1.0 - drop_connect_rate\n",
    "    mask = torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype, device=inputs.device) + keep_prob\n",
    "    mask = torch.floor(mask)  # Either 1 or 0\n",
    "    return inputs * mask / keep_prob\n",
    "\n",
    "\n",
    "# Call same padding methods, given the image size\n",
    "def get_same_static_padding_conv2d(image_size=None):\n",
    "    return partial(create_conv2d, image_size=image_size)\n",
    "\n",
    "\n",
    "def Conv2d(in_channels,out_channels,kernel_size, **kwargs):\n",
    "    return create_conv2d(in_chs=in_channels, out_chs=out_channels, kernel_size=kernel_size, **kwargs)\n",
    "\n",
    "\n",
    "# Custom same padding for the Cov2d for Pytorch\n",
    "# Static same padding based on the fixed image size\n",
    "class Conv2dSamePadding(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, image_size, **kwargs):\n",
    "\n",
    "        super().__init__(in_channels, out_channels, kernel_size, **kwargs)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [self.stride[0]] * 2  # Force stride to be tuple\n",
    "\n",
    "        assert image_size is not None\n",
    "        ih, iw = image_size if type(image_size) == list else [image_size, image_size]\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "\n",
    "        # Fill with Zero for the both left and right padding area\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            self.static_padding = nn.ZeroPad2d(\n",
    "                (pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))  ## Padding left and right\n",
    "        else:\n",
    "            ## No padding, leave input\n",
    "            self.static_padding = Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.static_padding(x)  ## The padding image\n",
    "        x = nn.functional.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Identity layer\n",
    "# Return the output same with the input\n",
    "class Identity(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kp4S96j2iqn0"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sequeeze and Excitation layer\n",
    "class Sequeeze_Excitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduced_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.se_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=reduced_channel, kernel_size=1, padding=0,bias=True),\n",
    "            EfficientSwish(),\n",
    "            nn.Conv2d(in_channels=reduced_channel, out_channels=in_channels, kernel_size=1, padding=0,bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_se = torch.sigmoid(self.se_layer(self.pooling(x)))\n",
    "        return x_se * x\n",
    "\n",
    "# Mobile Inverted Residual Bottleneck Block With the SE layer\n",
    "# Bottleneck architecture begins with 1x1 and ends with 1x1\n",
    "class MBCov_Block(nn.Module):\n",
    "    def __init__(self, block_args, batch_norm_momentum, batch_norm_epsilon, image_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_args = block_args\n",
    "\n",
    "        # Conv2d = get_same_static_padding_conv2d(image_size=image_size)\n",
    "\n",
    "        # Pointwise Conv (Expand layer) k1x1\n",
    "        expand_channels = block_args.input_channels * block_args.expand_ratio\n",
    "\n",
    "        if block_args.expand_ratio > 1:\n",
    "            self.expand_conv = nn.Sequential(\n",
    "                Conv2d(in_channels=block_args.input_channels, out_channels=expand_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(num_features=expand_channels, momentum=batch_norm_momentum, eps=batch_norm_epsilon),\n",
    "                EfficientSwish()\n",
    "            )\n",
    "\n",
    "        # Depthwise Conv (Through groups)\n",
    "        # print(expand_channels)\n",
    "        self.depthwise_conv = nn.Sequential(\n",
    "            Conv2d(in_channels=expand_channels, out_channels=expand_channels, kernel_size=block_args.kernel_size,\n",
    "                   stride=block_args.strides, depthwise=True, bias=False),\n",
    "            nn.BatchNorm2d(num_features=expand_channels, momentum=batch_norm_momentum, eps=batch_norm_epsilon),\n",
    "            EfficientSwish(),\n",
    "        )\n",
    "\n",
    "        # Squeeze and Excitation layer\n",
    "        if block_args.se_ratio:\n",
    "            reduced_channel = max(1, int(block_args.input_channels * block_args.se_ratio))\n",
    "            self.se_layer = Sequeeze_Excitation(expand_channels,reduced_channel)\n",
    "\n",
    "        # Pointwise Conv (Expand layer) k 1x1\n",
    "        self.output_conv = nn.Sequential(\n",
    "            Conv2d(in_channels=expand_channels, out_channels=block_args.output_channels, kernel_size=1, stride=1,\n",
    "                   bias=False),\n",
    "            nn.BatchNorm2d(num_features=block_args.output_channels, momentum=batch_norm_momentum,\n",
    "                           eps=batch_norm_epsilon),\n",
    "            EfficientSwish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, drop_connect_rate=None):\n",
    "        x = inputs\n",
    "\n",
    "        if self.block_args.expand_ratio > 1:\n",
    "            x = self.expand_conv(x)\n",
    "\n",
    "        x = self.depthwise_conv(x)\n",
    "        if self.block_args.se_ratio > 0:\n",
    "            x = self.se_layer(x)\n",
    "        x = self.output_conv(x)\n",
    "\n",
    "        # id skip, drop connect\n",
    "      \n",
    "        if self.block_args.id_skip and self.block_args.strides == 1 and \\\n",
    "                self.block_args.input_channels == self.block_args.output_channels:\n",
    "            if drop_connect_rate and self.training:\n",
    "                x = drop_connect(x, drop_connect_rate)\n",
    "            x = x + inputs\n",
    "        return x\n",
    "\n",
    "\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, model_name, width_coeff, depth_coeff, resolu, dropout_rate, depth_divisor, batch_norm_epsilon,\n",
    "                 batch_norm_momentum, drop_connect_rate, num_output, blocks_args=BLOCKS_ARGS):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_norm_mom = 1-batch_norm_momentum\n",
    "        self.drop_connect_rate = drop_connect_rate\n",
    "        self.blocks_args = blocks_args\n",
    "        self.model_name = model_name\n",
    "        self.archtecture = []\n",
    "\n",
    "        # Conv2d = get_same_static_padding_conv2d(image_size=resolu)\n",
    "\n",
    "        # Stem\n",
    "        out_channel = round_filters(32, width_coeff, depth_divisor)\n",
    "        # print(out_channel)\n",
    "        self.stem = nn.Sequential(\n",
    "            Conv2d(3, out_channel, kernel_size=3, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(num_features=out_channel, eps=batch_norm_epsilon, momentum=batch_norm_momentum),\n",
    "            EfficientSwish()\n",
    "        )\n",
    "\n",
    "        layer = \"Conv{:d}x{:d} in: {:d}, out:{:d}\\n\".format(3, 3, 3, out_channel)\n",
    "        self.archtecture.append(layer)\n",
    "\n",
    "        # Blocks\n",
    "        self.blocks = nn.ModuleList([])  ## like the module link list, append layers\n",
    "        \n",
    "        for i, block_args in enumerate(blocks_args):\n",
    "\n",
    "            block_args = block_args._replace(\n",
    "                input_channels=round_filters(block_args.input_channels, width_coeff, depth_divisor),\n",
    "                output_channels=round_filters(block_args.output_channels, width_coeff, depth_divisor),\n",
    "                num_repeat=round_repeated(block_args.num_repeat, depth_coeff)\n",
    "            )\n",
    "\n",
    "            self.blocks.append(\n",
    "                MBCov_Block(block_args, batch_norm_momentum, batch_norm_epsilon, resolu))\n",
    "\n",
    "            layer = \"MB_Conv{:d} {:d}x{:d} in: {:d}, out:{:d}\\n\".format(block_args.expand_ratio,\n",
    "                                                                        block_args.kernel_size,\n",
    "                                                                        block_args.kernel_size,\n",
    "                                                                        block_args.input_channels,\n",
    "                                                                        block_args.output_channels)\n",
    "            self.archtecture.append(layer)\n",
    "\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_channels=block_args.output_channels, strides=1)\n",
    "\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self.blocks.append(\n",
    "                    MBCov_Block(block_args, batch_norm_momentum, batch_norm_epsilon, resolu))\n",
    "\n",
    "                layer = \"MB_Conv{:d} {:d}x{:d} in: {:d}, out:{:d}\\n\".format(block_args.expand_ratio,\n",
    "                                                                            block_args.kernel_size,\n",
    "                                                                            block_args.kernel_size,\n",
    "                                                                            block_args.input_channels,\n",
    "                                                                            block_args.output_channels)\n",
    "                self.archtecture.append(layer)\n",
    "\n",
    "        # Head\n",
    "        in_channel = block_args.output_channels\n",
    "        out_channel = round_filters(1280, width_coeff, depth_divisor)\n",
    "        self.head = nn.Sequential(\n",
    "            Conv2d(in_channel, out_channel, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=out_channel, eps=batch_norm_epsilon, momentum=batch_norm_momentum),\n",
    "            EfficientSwish(),\n",
    "        )\n",
    "        layer = \"Conv{:d}x{:d} in: {:d}, out:{:d}\\n\".format(1, 1, in_channel, out_channel)\n",
    "        self.archtecture.append(layer)\n",
    "\n",
    "        # FC\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            Flatten(),\n",
    "            nn.Dropout2d(dropout_rate),\n",
    "            nn.Linear(out_channel, num_output),\n",
    "        )\n",
    "        layer = \"FC in: {:d}, out:{:d}\\n\".format(out_channel, num_output)\n",
    "        self.archtecture.append(layer)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        batch_size = list(inputs.size())[0]\n",
    "\n",
    "        x = self.stem(inputs)\n",
    "\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if self.drop_connect_rate:\n",
    "                drop_connect_rate = self.drop_connect_rate * i / len(self.blocks)\n",
    "                x = block(x, drop_connect_rate)\n",
    "\n",
    "        x = self.head(x)\n",
    "\n",
    "        x = self.FC(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def model_structure(self):\n",
    "        print(self.model_name)\n",
    "        print()\n",
    "        for idx, layer in enumerate(self.archtecture):\n",
    "            print(str(idx) + \"\\t\" + layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REYN14Q67bjy"
   },
   "outputs": [],
   "source": [
    "def EfficientNetB0(num_oup):\n",
    "    return EfficientNet(\"efficientNet-B0\", 1.0, 1.0, 224, 0.2, depth_divisor=8, batch_norm_epsilon=0.001,\n",
    "                        batch_norm_momentum=0.99, drop_connect_rate=0.2, num_output=num_oup)\n",
    "    \n",
    "def EfficientNetB1(num_oup):\n",
    "    return EfficientNet(\"efficientNet-B1\",1.0, 1.1, 240, 0.2, depth_divisor=8, batch_norm_epsilon=0.001,\n",
    "                        batch_norm_momentum=0.99, drop_connect_rate=0.2, num_output=num_oup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiYaqU1WKm-i"
   },
   "outputs": [],
   "source": [
    "def testing(model, test_loader, criterion):\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for inputs, targets in test_loader:\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            test_loss += criterion(outputs, targets).item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            total += 1\n",
    "    \n",
    "    print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {:.4f}\\n\".format(test_loss/total, correct / len(test_loader.dataset)))\n",
    "\n",
    "    return test_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMTYYTnYYJlA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def training(model, train_loader, optimizer, criterion, epoch):\n",
    "    training_loss = 0\n",
    "    model.train()\n",
    "    bi = 200\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        if batch_idx % bi == bi-1:  # print every 1000 mini-batches\n",
    "            print('[epoch: %d, batch: %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, training_loss / bi))\n",
    "            training_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPYUQuY51q1D"
   },
   "outputs": [],
   "source": [
    "\n",
    "def ImageProcessing():\n",
    "    transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "    train_dat = datasets.CIFAR10(\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dat, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    test_dat = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dat, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def imageConvert(tensor):\n",
    "    image = tensor.clone().detach().numpy()\n",
    "    image = image.transpose(1, 2, 0)\n",
    "    print(image.shape)\n",
    "    image = image * np.array((0.4914, 0.4822, 0.4465)) + np.array((0.247, 0.243, 0.261))\n",
    "    image = image.clip(0, 1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def imageshow(loader, classes):\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    print(labels)\n",
    "    plt.imshow(imageConvert(make_grid(images)))\n",
    "    plt.show()\n",
    "    print(' '.join('%5s' % classes[labels[j]] for j in range(10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duKXoVUNxjy7"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(lr, optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 0.97 every 2.4 epochs\"\"\"\n",
    "    lr = lr * (0.97 ** (epoch // 2))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def print_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"Epoch: [{}] Current learning rate (lr) = {}\".format(\n",
    "                                                    epoch, param_group['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RQsrscB1sjO"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    # classes = (\n",
    "    # 'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    # 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    # 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    # 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    # 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    # 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    # 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    # 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    # 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    # 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    # 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    # 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    # 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    # 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    # 'worm')\n",
    "\n",
    "    train_loader, test_loader = ImageProcessing()\n",
    "    \n",
    "    # print(len(classes))\n",
    "    # imageshow(train_loader, classes)\n",
    "\n",
    "    momentum = 0.9\n",
    "    epochs = 20\n",
    "    decay = 1e-5\n",
    "    eps = 1e-3\n",
    "    lr = 0.001\n",
    "\n",
    "    model = EfficientNetB0(10).to(device)\n",
    "\n",
    "    summary(model,(3,224,224),batch_size=10)\n",
    "\n",
    "    # model.model_structure()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(), alpha=0.9, lr = 0.016, eps = 1e-3, weight_decay =1e-5, momentum =0.9)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr= lr, momentum=momentum, weight_decay=decay)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-5)\n",
    "\n",
    "    # reduce_lr = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "    reduce_lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print_learning_rate(optimizer, epoch+1)\n",
    "        training(model, train_loader, optimizer, criterion, epoch)\n",
    "        loss = testing(model, test_loader, criterion)\n",
    "        reduce_lr.step(loss)\n",
    "\n",
    "        # adjust_learning_rate(lr, optimizer, epoch+1)\n",
    "    \n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1b4ff6f25e444235aeb6e5dc19098743",
      "d44c043f8a1f43d0b985e4b12ffb9b03",
      "c10c093c72e145209e099043f58f7755",
      "28b5454f9e104c6c9bbb237378c54ee3",
      "10dfc3fd6a964c3a9ec5838f7764e581",
      "71a70c412cbe4eb0801877cbbd288c96",
      "fa485a2a64bc4e87a666aa3ab3a2bbdd",
      "828bdfcd1fc34cb294e41516945780b0"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4516841,
     "status": "ok",
     "timestamp": 1586111288590,
     "user": {
      "displayName": "Yurun SONG",
      "photoUrl": "",
      "userId": "00512124433136381755"
     },
     "user_tz": -60
    },
    "id": "P6xF-VNHsGl9",
    "outputId": "c22a6282-35fc-4bec-f88f-7eab71ceb052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4ff6f25e444235aeb6e5dc19098743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [10, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [10, 32, 112, 112]              64\n",
      "    EfficientSwish-3         [10, 32, 112, 112]               0\n",
      "            Conv2d-4         [10, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [10, 32, 112, 112]              64\n",
      "    EfficientSwish-6         [10, 32, 112, 112]               0\n",
      " AdaptiveAvgPool2d-7             [10, 32, 1, 1]               0\n",
      "            Conv2d-8              [10, 8, 1, 1]             264\n",
      "    EfficientSwish-9              [10, 8, 1, 1]               0\n",
      "           Conv2d-10             [10, 32, 1, 1]             288\n",
      "Sequeeze_Excitation-11         [10, 32, 112, 112]               0\n",
      "           Conv2d-12         [10, 16, 112, 112]             512\n",
      "      BatchNorm2d-13         [10, 16, 112, 112]              32\n",
      "   EfficientSwish-14         [10, 16, 112, 112]               0\n",
      "      MBCov_Block-15         [10, 16, 112, 112]               0\n",
      "           Conv2d-16         [10, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-17         [10, 96, 112, 112]             192\n",
      "   EfficientSwish-18         [10, 96, 112, 112]               0\n",
      "           Conv2d-19           [10, 96, 56, 56]             864\n",
      "      BatchNorm2d-20           [10, 96, 56, 56]             192\n",
      "   EfficientSwish-21           [10, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-22             [10, 96, 1, 1]               0\n",
      "           Conv2d-23              [10, 4, 1, 1]             388\n",
      "   EfficientSwish-24              [10, 4, 1, 1]               0\n",
      "           Conv2d-25             [10, 96, 1, 1]             480\n",
      "Sequeeze_Excitation-26           [10, 96, 56, 56]               0\n",
      "           Conv2d-27           [10, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-28           [10, 24, 56, 56]              48\n",
      "   EfficientSwish-29           [10, 24, 56, 56]               0\n",
      "      MBCov_Block-30           [10, 24, 56, 56]               0\n",
      "           Conv2d-31          [10, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-32          [10, 144, 56, 56]             288\n",
      "   EfficientSwish-33          [10, 144, 56, 56]               0\n",
      "           Conv2d-34          [10, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-35          [10, 144, 56, 56]             288\n",
      "   EfficientSwish-36          [10, 144, 56, 56]               0\n",
      "AdaptiveAvgPool2d-37            [10, 144, 1, 1]               0\n",
      "           Conv2d-38              [10, 6, 1, 1]             870\n",
      "   EfficientSwish-39              [10, 6, 1, 1]               0\n",
      "           Conv2d-40            [10, 144, 1, 1]           1,008\n",
      "Sequeeze_Excitation-41          [10, 144, 56, 56]               0\n",
      "           Conv2d-42           [10, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-43           [10, 24, 56, 56]              48\n",
      "   EfficientSwish-44           [10, 24, 56, 56]               0\n",
      "      MBCov_Block-45           [10, 24, 56, 56]               0\n",
      "           Conv2d-46          [10, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-47          [10, 144, 56, 56]             288\n",
      "   EfficientSwish-48          [10, 144, 56, 56]               0\n",
      "           Conv2d-49          [10, 144, 28, 28]           3,600\n",
      "      BatchNorm2d-50          [10, 144, 28, 28]             288\n",
      "   EfficientSwish-51          [10, 144, 28, 28]               0\n",
      "AdaptiveAvgPool2d-52            [10, 144, 1, 1]               0\n",
      "           Conv2d-53              [10, 6, 1, 1]             870\n",
      "   EfficientSwish-54              [10, 6, 1, 1]               0\n",
      "           Conv2d-55            [10, 144, 1, 1]           1,008\n",
      "Sequeeze_Excitation-56          [10, 144, 28, 28]               0\n",
      "           Conv2d-57           [10, 40, 28, 28]           5,760\n",
      "      BatchNorm2d-58           [10, 40, 28, 28]              80\n",
      "   EfficientSwish-59           [10, 40, 28, 28]               0\n",
      "      MBCov_Block-60           [10, 40, 28, 28]               0\n",
      "           Conv2d-61          [10, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-62          [10, 240, 28, 28]             480\n",
      "   EfficientSwish-63          [10, 240, 28, 28]               0\n",
      "           Conv2d-64          [10, 240, 28, 28]           6,000\n",
      "      BatchNorm2d-65          [10, 240, 28, 28]             480\n",
      "   EfficientSwish-66          [10, 240, 28, 28]               0\n",
      "AdaptiveAvgPool2d-67            [10, 240, 1, 1]               0\n",
      "           Conv2d-68             [10, 10, 1, 1]           2,410\n",
      "   EfficientSwish-69             [10, 10, 1, 1]               0\n",
      "           Conv2d-70            [10, 240, 1, 1]           2,640\n",
      "Sequeeze_Excitation-71          [10, 240, 28, 28]               0\n",
      "           Conv2d-72           [10, 40, 28, 28]           9,600\n",
      "      BatchNorm2d-73           [10, 40, 28, 28]              80\n",
      "   EfficientSwish-74           [10, 40, 28, 28]               0\n",
      "      MBCov_Block-75           [10, 40, 28, 28]               0\n",
      "           Conv2d-76          [10, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-77          [10, 240, 28, 28]             480\n",
      "   EfficientSwish-78          [10, 240, 28, 28]               0\n",
      "           Conv2d-79          [10, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-80          [10, 240, 14, 14]             480\n",
      "   EfficientSwish-81          [10, 240, 14, 14]               0\n",
      "AdaptiveAvgPool2d-82            [10, 240, 1, 1]               0\n",
      "           Conv2d-83             [10, 10, 1, 1]           2,410\n",
      "   EfficientSwish-84             [10, 10, 1, 1]               0\n",
      "           Conv2d-85            [10, 240, 1, 1]           2,640\n",
      "Sequeeze_Excitation-86          [10, 240, 14, 14]               0\n",
      "           Conv2d-87           [10, 80, 14, 14]          19,200\n",
      "      BatchNorm2d-88           [10, 80, 14, 14]             160\n",
      "   EfficientSwish-89           [10, 80, 14, 14]               0\n",
      "      MBCov_Block-90           [10, 80, 14, 14]               0\n",
      "           Conv2d-91          [10, 480, 14, 14]          38,400\n",
      "      BatchNorm2d-92          [10, 480, 14, 14]             960\n",
      "   EfficientSwish-93          [10, 480, 14, 14]               0\n",
      "           Conv2d-94          [10, 480, 14, 14]           4,320\n",
      "      BatchNorm2d-95          [10, 480, 14, 14]             960\n",
      "   EfficientSwish-96          [10, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-97            [10, 480, 1, 1]               0\n",
      "           Conv2d-98             [10, 20, 1, 1]           9,620\n",
      "   EfficientSwish-99             [10, 20, 1, 1]               0\n",
      "          Conv2d-100            [10, 480, 1, 1]          10,080\n",
      "Sequeeze_Excitation-101          [10, 480, 14, 14]               0\n",
      "          Conv2d-102           [10, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-103           [10, 80, 14, 14]             160\n",
      "  EfficientSwish-104           [10, 80, 14, 14]               0\n",
      "     MBCov_Block-105           [10, 80, 14, 14]               0\n",
      "          Conv2d-106          [10, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-107          [10, 480, 14, 14]             960\n",
      "  EfficientSwish-108          [10, 480, 14, 14]               0\n",
      "          Conv2d-109          [10, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-110          [10, 480, 14, 14]             960\n",
      "  EfficientSwish-111          [10, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-112            [10, 480, 1, 1]               0\n",
      "          Conv2d-113             [10, 20, 1, 1]           9,620\n",
      "  EfficientSwish-114             [10, 20, 1, 1]               0\n",
      "          Conv2d-115            [10, 480, 1, 1]          10,080\n",
      "Sequeeze_Excitation-116          [10, 480, 14, 14]               0\n",
      "          Conv2d-117           [10, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-118           [10, 80, 14, 14]             160\n",
      "  EfficientSwish-119           [10, 80, 14, 14]               0\n",
      "     MBCov_Block-120           [10, 80, 14, 14]               0\n",
      "          Conv2d-121          [10, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-122          [10, 480, 14, 14]             960\n",
      "  EfficientSwish-123          [10, 480, 14, 14]               0\n",
      "          Conv2d-124          [10, 480, 14, 14]          12,000\n",
      "     BatchNorm2d-125          [10, 480, 14, 14]             960\n",
      "  EfficientSwish-126          [10, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-127            [10, 480, 1, 1]               0\n",
      "          Conv2d-128             [10, 20, 1, 1]           9,620\n",
      "  EfficientSwish-129             [10, 20, 1, 1]               0\n",
      "          Conv2d-130            [10, 480, 1, 1]          10,080\n",
      "Sequeeze_Excitation-131          [10, 480, 14, 14]               0\n",
      "          Conv2d-132          [10, 112, 14, 14]          53,760\n",
      "     BatchNorm2d-133          [10, 112, 14, 14]             224\n",
      "  EfficientSwish-134          [10, 112, 14, 14]               0\n",
      "     MBCov_Block-135          [10, 112, 14, 14]               0\n",
      "          Conv2d-136          [10, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-137          [10, 672, 14, 14]           1,344\n",
      "  EfficientSwish-138          [10, 672, 14, 14]               0\n",
      "          Conv2d-139          [10, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-140          [10, 672, 14, 14]           1,344\n",
      "  EfficientSwish-141          [10, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-142            [10, 672, 1, 1]               0\n",
      "          Conv2d-143             [10, 28, 1, 1]          18,844\n",
      "  EfficientSwish-144             [10, 28, 1, 1]               0\n",
      "          Conv2d-145            [10, 672, 1, 1]          19,488\n",
      "Sequeeze_Excitation-146          [10, 672, 14, 14]               0\n",
      "          Conv2d-147          [10, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-148          [10, 112, 14, 14]             224\n",
      "  EfficientSwish-149          [10, 112, 14, 14]               0\n",
      "     MBCov_Block-150          [10, 112, 14, 14]               0\n",
      "          Conv2d-151          [10, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-152          [10, 672, 14, 14]           1,344\n",
      "  EfficientSwish-153          [10, 672, 14, 14]               0\n",
      "          Conv2d-154          [10, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-155          [10, 672, 14, 14]           1,344\n",
      "  EfficientSwish-156          [10, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-157            [10, 672, 1, 1]               0\n",
      "          Conv2d-158             [10, 28, 1, 1]          18,844\n",
      "  EfficientSwish-159             [10, 28, 1, 1]               0\n",
      "          Conv2d-160            [10, 672, 1, 1]          19,488\n",
      "Sequeeze_Excitation-161          [10, 672, 14, 14]               0\n",
      "          Conv2d-162          [10, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-163          [10, 112, 14, 14]             224\n",
      "  EfficientSwish-164          [10, 112, 14, 14]               0\n",
      "     MBCov_Block-165          [10, 112, 14, 14]               0\n",
      "          Conv2d-166          [10, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-167          [10, 672, 14, 14]           1,344\n",
      "  EfficientSwish-168          [10, 672, 14, 14]               0\n",
      "          Conv2d-169            [10, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-170            [10, 672, 7, 7]           1,344\n",
      "  EfficientSwish-171            [10, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-172            [10, 672, 1, 1]               0\n",
      "          Conv2d-173             [10, 28, 1, 1]          18,844\n",
      "  EfficientSwish-174             [10, 28, 1, 1]               0\n",
      "          Conv2d-175            [10, 672, 1, 1]          19,488\n",
      "Sequeeze_Excitation-176            [10, 672, 7, 7]               0\n",
      "          Conv2d-177            [10, 192, 7, 7]         129,024\n",
      "     BatchNorm2d-178            [10, 192, 7, 7]             384\n",
      "  EfficientSwish-179            [10, 192, 7, 7]               0\n",
      "     MBCov_Block-180            [10, 192, 7, 7]               0\n",
      "          Conv2d-181           [10, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-182           [10, 1152, 7, 7]           2,304\n",
      "  EfficientSwish-183           [10, 1152, 7, 7]               0\n",
      "          Conv2d-184           [10, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-185           [10, 1152, 7, 7]           2,304\n",
      "  EfficientSwish-186           [10, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-187           [10, 1152, 1, 1]               0\n",
      "          Conv2d-188             [10, 48, 1, 1]          55,344\n",
      "  EfficientSwish-189             [10, 48, 1, 1]               0\n",
      "          Conv2d-190           [10, 1152, 1, 1]          56,448\n",
      "Sequeeze_Excitation-191           [10, 1152, 7, 7]               0\n",
      "          Conv2d-192            [10, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-193            [10, 192, 7, 7]             384\n",
      "  EfficientSwish-194            [10, 192, 7, 7]               0\n",
      "     MBCov_Block-195            [10, 192, 7, 7]               0\n",
      "          Conv2d-196           [10, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-197           [10, 1152, 7, 7]           2,304\n",
      "  EfficientSwish-198           [10, 1152, 7, 7]               0\n",
      "          Conv2d-199           [10, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-200           [10, 1152, 7, 7]           2,304\n",
      "  EfficientSwish-201           [10, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-202           [10, 1152, 1, 1]               0\n",
      "          Conv2d-203             [10, 48, 1, 1]          55,344\n",
      "  EfficientSwish-204             [10, 48, 1, 1]               0\n",
      "          Conv2d-205           [10, 1152, 1, 1]          56,448\n",
      "Sequeeze_Excitation-206           [10, 1152, 7, 7]               0\n",
      "          Conv2d-207            [10, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-208            [10, 192, 7, 7]             384\n",
      "  EfficientSwish-209            [10, 192, 7, 7]               0\n",
      "     MBCov_Block-210            [10, 192, 7, 7]               0\n",
      "          Conv2d-211           [10, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-212           [10, 1152, 7, 7]           2,304\n",
      "  EfficientSwish-213           [10, 1152, 7, 7]               0\n",
      "          Conv2d-214           [10, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-215           [10, 1152, 7, 7]           2,304\n",
      "  EfficientSwish-216           [10, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-217           [10, 1152, 1, 1]               0\n",
      "          Conv2d-218             [10, 48, 1, 1]          55,344\n",
      "  EfficientSwish-219             [10, 48, 1, 1]               0\n",
      "          Conv2d-220           [10, 1152, 1, 1]          56,448\n",
      "Sequeeze_Excitation-221           [10, 1152, 7, 7]               0\n",
      "          Conv2d-222            [10, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-223            [10, 192, 7, 7]             384\n",
      "  EfficientSwish-224            [10, 192, 7, 7]               0\n",
      "     MBCov_Block-225            [10, 192, 7, 7]               0\n",
      "          Conv2d-226           [10, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-227           [10, 1152, 7, 7]           2,304\n",
      "  EfficientSwish-228           [10, 1152, 7, 7]               0\n",
      "          Conv2d-229           [10, 1152, 7, 7]          10,368\n",
      "     BatchNorm2d-230           [10, 1152, 7, 7]           2,304\n",
      "  EfficientSwish-231           [10, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-232           [10, 1152, 1, 1]               0\n",
      "          Conv2d-233             [10, 48, 1, 1]          55,344\n",
      "  EfficientSwish-234             [10, 48, 1, 1]               0\n",
      "          Conv2d-235           [10, 1152, 1, 1]          56,448\n",
      "Sequeeze_Excitation-236           [10, 1152, 7, 7]               0\n",
      "          Conv2d-237            [10, 320, 7, 7]         368,640\n",
      "     BatchNorm2d-238            [10, 320, 7, 7]             640\n",
      "  EfficientSwish-239            [10, 320, 7, 7]               0\n",
      "     MBCov_Block-240            [10, 320, 7, 7]               0\n",
      "          Conv2d-241           [10, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-242           [10, 1280, 7, 7]           2,560\n",
      "  EfficientSwish-243           [10, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-244           [10, 1280, 1, 1]               0\n",
      "         Flatten-245                 [10, 1280]               0\n",
      "       Dropout2d-246                 [10, 1280]               0\n",
      "          Linear-247                   [10, 10]          12,810\n",
      "================================================================\n",
      "Total params: 4,020,358\n",
      "Trainable params: 4,020,358\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 5.74\n",
      "Forward/backward pass size (MB): 1764.09\n",
      "Params size (MB): 15.34\n",
      "Estimated Total Size (MB): 1785.17\n",
      "----------------------------------------------------------------\n",
      "Epoch: [1] Current learning rate (lr) = 0.001\n",
      "[epoch: 1, batch:   200] loss: 1.982\n",
      "[epoch: 1, batch:   400] loss: 1.706\n",
      "[epoch: 1, batch:   600] loss: 1.519\n",
      "[epoch: 1, batch:   800] loss: 1.335\n",
      "[epoch: 1, batch:  1000] loss: 1.230\n",
      "[epoch: 1, batch:  1200] loss: 1.159\n",
      "[epoch: 1, batch:  1400] loss: 1.069\n",
      "\n",
      "Test set: Average loss: 1.1706, Accuracy: 0.6043\n",
      "\n",
      "Epoch: [2] Current learning rate (lr) = 0.001\n",
      "[epoch: 2, batch:   200] loss: 0.957\n",
      "[epoch: 2, batch:   400] loss: 0.906\n",
      "[epoch: 2, batch:   600] loss: 0.875\n",
      "[epoch: 2, batch:   800] loss: 0.829\n",
      "[epoch: 2, batch:  1000] loss: 0.766\n",
      "[epoch: 2, batch:  1200] loss: 0.753\n",
      "[epoch: 2, batch:  1400] loss: 0.709\n",
      "\n",
      "Test set: Average loss: 0.8516, Accuracy: 0.7111\n",
      "\n",
      "Epoch: [3] Current learning rate (lr) = 0.001\n",
      "[epoch: 3, batch:   200] loss: 0.656\n",
      "[epoch: 3, batch:   400] loss: 0.636\n",
      "[epoch: 3, batch:   600] loss: 0.642\n",
      "[epoch: 3, batch:   800] loss: 0.610\n",
      "[epoch: 3, batch:  1000] loss: 0.565\n",
      "[epoch: 3, batch:  1200] loss: 0.564\n",
      "[epoch: 3, batch:  1400] loss: 0.527\n",
      "\n",
      "Test set: Average loss: 0.7396, Accuracy: 0.7546\n",
      "\n",
      "Epoch: [4] Current learning rate (lr) = 0.001\n",
      "[epoch: 4, batch:   200] loss: 0.505\n",
      "[epoch: 4, batch:   400] loss: 0.497\n",
      "[epoch: 4, batch:   600] loss: 0.512\n",
      "[epoch: 4, batch:   800] loss: 0.468\n",
      "[epoch: 4, batch:  1000] loss: 0.431\n",
      "[epoch: 4, batch:  1200] loss: 0.433\n",
      "[epoch: 4, batch:  1400] loss: 0.407\n",
      "\n",
      "Test set: Average loss: 0.6978, Accuracy: 0.7745\n",
      "\n",
      "Epoch: [5] Current learning rate (lr) = 0.001\n",
      "[epoch: 5, batch:   200] loss: 0.388\n",
      "[epoch: 5, batch:   400] loss: 0.379\n",
      "[epoch: 5, batch:   600] loss: 0.394\n",
      "[epoch: 5, batch:   800] loss: 0.366\n",
      "[epoch: 5, batch:  1000] loss: 0.329\n",
      "[epoch: 5, batch:  1200] loss: 0.337\n",
      "[epoch: 5, batch:  1400] loss: 0.295\n",
      "\n",
      "Test set: Average loss: 0.7403, Accuracy: 0.7811\n",
      "\n",
      "Epoch: [6] Current learning rate (lr) = 0.001\n",
      "[epoch: 6, batch:   200] loss: 0.307\n",
      "[epoch: 6, batch:   400] loss: 0.291\n",
      "[epoch: 6, batch:   600] loss: 0.311\n",
      "[epoch: 6, batch:   800] loss: 0.285\n",
      "[epoch: 6, batch:  1000] loss: 0.234\n",
      "[epoch: 6, batch:  1200] loss: 0.257\n",
      "[epoch: 6, batch:  1400] loss: 0.228\n",
      "\n",
      "Test set: Average loss: 0.7465, Accuracy: 0.7930\n",
      "\n",
      "Epoch: [7] Current learning rate (lr) = 0.001\n",
      "[epoch: 7, batch:   200] loss: 0.243\n",
      "[epoch: 7, batch:   400] loss: 0.229\n",
      "[epoch: 7, batch:   600] loss: 0.229\n",
      "[epoch: 7, batch:   800] loss: 0.212\n",
      "[epoch: 7, batch:  1000] loss: 0.189\n",
      "[epoch: 7, batch:  1200] loss: 0.209\n",
      "[epoch: 7, batch:  1400] loss: 0.187\n",
      "\n",
      "Test set: Average loss: 0.8215, Accuracy: 0.7886\n",
      "\n",
      "Epoch: [8] Current learning rate (lr) = 0.0005\n",
      "[epoch: 8, batch:   200] loss: 0.156\n",
      "[epoch: 8, batch:   400] loss: 0.129\n",
      "[epoch: 8, batch:   600] loss: 0.114\n",
      "[epoch: 8, batch:   800] loss: 0.116\n",
      "[epoch: 8, batch:  1000] loss: 0.084\n",
      "[epoch: 8, batch:  1200] loss: 0.077\n",
      "[epoch: 8, batch:  1400] loss: 0.070\n",
      "\n",
      "Test set: Average loss: 0.8540, Accuracy: 0.8132\n",
      "\n",
      "Epoch: [9] Current learning rate (lr) = 0.0005\n",
      "[epoch: 9, batch:   200] loss: 0.065\n",
      "[epoch: 9, batch:   400] loss: 0.057\n",
      "[epoch: 9, batch:   600] loss: 0.054\n",
      "[epoch: 9, batch:   800] loss: 0.047\n",
      "[epoch: 9, batch:  1000] loss: 0.050\n",
      "[epoch: 9, batch:  1200] loss: 0.050\n",
      "[epoch: 9, batch:  1400] loss: 0.043\n",
      "\n",
      "Test set: Average loss: 1.0304, Accuracy: 0.8099\n",
      "\n",
      "Epoch: [10] Current learning rate (lr) = 0.0005\n",
      "[epoch: 10, batch:   200] loss: 0.057\n",
      "[epoch: 10, batch:   400] loss: 0.059\n",
      "[epoch: 10, batch:   600] loss: 0.050\n",
      "[epoch: 10, batch:   800] loss: 0.053\n",
      "[epoch: 10, batch:  1000] loss: 0.046\n",
      "[epoch: 10, batch:  1200] loss: 0.049\n",
      "[epoch: 10, batch:  1400] loss: 0.052\n",
      "\n",
      "Test set: Average loss: 1.1467, Accuracy: 0.7990\n",
      "\n",
      "Epoch: [11] Current learning rate (lr) = 0.00025\n",
      "[epoch: 11, batch:   200] loss: 0.040\n",
      "[epoch: 11, batch:   400] loss: 0.033\n",
      "[epoch: 11, batch:   600] loss: 0.029\n",
      "[epoch: 11, batch:   800] loss: 0.027\n",
      "[epoch: 11, batch:  1000] loss: 0.017\n",
      "[epoch: 11, batch:  1200] loss: 0.014\n",
      "[epoch: 11, batch:  1400] loss: 0.012\n",
      "\n",
      "Test set: Average loss: 1.0008, Accuracy: 0.8245\n",
      "\n",
      "Epoch: [12] Current learning rate (lr) = 0.00025\n",
      "[epoch: 12, batch:   200] loss: 0.014\n",
      "[epoch: 12, batch:   400] loss: 0.012\n",
      "[epoch: 12, batch:   600] loss: 0.011\n",
      "[epoch: 12, batch:   800] loss: 0.013\n",
      "[epoch: 12, batch:  1000] loss: 0.009\n",
      "[epoch: 12, batch:  1200] loss: 0.008\n",
      "[epoch: 12, batch:  1400] loss: 0.008\n",
      "\n",
      "Test set: Average loss: 1.1001, Accuracy: 0.8236\n",
      "\n",
      "Epoch: [13] Current learning rate (lr) = 0.00025\n",
      "[epoch: 13, batch:   200] loss: 0.007\n",
      "[epoch: 13, batch:   400] loss: 0.006\n",
      "[epoch: 13, batch:   600] loss: 0.009\n",
      "[epoch: 13, batch:   800] loss: 0.013\n",
      "[epoch: 13, batch:  1000] loss: 0.014\n",
      "[epoch: 13, batch:  1200] loss: 0.011\n",
      "[epoch: 13, batch:  1400] loss: 0.013\n",
      "\n",
      "Test set: Average loss: 1.2119, Accuracy: 0.8183\n",
      "\n",
      "Epoch: [14] Current learning rate (lr) = 0.000125\n",
      "[epoch: 14, batch:   200] loss: 0.014\n",
      "[epoch: 14, batch:   400] loss: 0.010\n",
      "[epoch: 14, batch:   600] loss: 0.013\n",
      "[epoch: 14, batch:   800] loss: 0.007\n",
      "[epoch: 14, batch:  1000] loss: 0.004\n",
      "[epoch: 14, batch:  1200] loss: 0.006\n",
      "[epoch: 14, batch:  1400] loss: 0.004\n",
      "\n",
      "Test set: Average loss: 1.0313, Accuracy: 0.8391\n",
      "\n",
      "Epoch: [15] Current learning rate (lr) = 0.000125\n",
      "[epoch: 15, batch:   200] loss: 0.004\n",
      "[epoch: 15, batch:   400] loss: 0.004\n",
      "[epoch: 15, batch:   600] loss: 0.004\n",
      "[epoch: 15, batch:   800] loss: 0.004\n",
      "[epoch: 15, batch:  1000] loss: 0.003\n",
      "[epoch: 15, batch:  1200] loss: 0.004\n",
      "[epoch: 15, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 1.1676, Accuracy: 0.8286\n",
      "\n",
      "Epoch: [16] Current learning rate (lr) = 0.000125\n",
      "[epoch: 16, batch:   200] loss: 0.003\n",
      "[epoch: 16, batch:   400] loss: 0.003\n",
      "[epoch: 16, batch:   600] loss: 0.004\n",
      "[epoch: 16, batch:   800] loss: 0.004\n",
      "[epoch: 16, batch:  1000] loss: 0.002\n",
      "[epoch: 16, batch:  1200] loss: 0.002\n",
      "[epoch: 16, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 1.2381, Accuracy: 0.8224\n",
      "\n",
      "Epoch: [17] Current learning rate (lr) = 6.25e-05\n",
      "[epoch: 17, batch:   200] loss: 0.002\n",
      "[epoch: 17, batch:   400] loss: 0.004\n",
      "[epoch: 17, batch:   600] loss: 0.003\n",
      "[epoch: 17, batch:   800] loss: 0.002\n",
      "[epoch: 17, batch:  1000] loss: 0.002\n",
      "[epoch: 17, batch:  1200] loss: 0.002\n",
      "[epoch: 17, batch:  1400] loss: 0.002\n",
      "\n",
      "Test set: Average loss: 1.1558, Accuracy: 0.8335\n",
      "\n",
      "Epoch: [18] Current learning rate (lr) = 6.25e-05\n",
      "[epoch: 18, batch:   200] loss: 0.001\n",
      "[epoch: 18, batch:   400] loss: 0.002\n",
      "[epoch: 18, batch:   600] loss: 0.002\n",
      "[epoch: 18, batch:   800] loss: 0.001\n",
      "[epoch: 18, batch:  1000] loss: 0.001\n",
      "[epoch: 18, batch:  1200] loss: 0.001\n",
      "[epoch: 18, batch:  1400] loss: 0.001\n",
      "\n",
      "Test set: Average loss: 1.2006, Accuracy: 0.8287\n",
      "\n",
      "Epoch: [19] Current learning rate (lr) = 6.25e-05\n",
      "[epoch: 19, batch:   200] loss: 0.002\n",
      "[epoch: 19, batch:   400] loss: 0.001\n",
      "[epoch: 19, batch:   600] loss: 0.001\n",
      "[epoch: 19, batch:   800] loss: 0.001\n",
      "[epoch: 19, batch:  1000] loss: 0.001\n",
      "[epoch: 19, batch:  1200] loss: 0.001\n",
      "[epoch: 19, batch:  1400] loss: 0.001\n",
      "\n",
      "Test set: Average loss: 1.2675, Accuracy: 0.8264\n",
      "\n",
      "Epoch: [20] Current learning rate (lr) = 3.125e-05\n",
      "[epoch: 20, batch:   200] loss: 0.001\n",
      "[epoch: 20, batch:   400] loss: 0.001\n",
      "[epoch: 20, batch:   600] loss: 0.001\n",
      "[epoch: 20, batch:   800] loss: 0.001\n",
      "[epoch: 20, batch:  1000] loss: 0.001\n",
      "[epoch: 20, batch:  1200] loss: 0.001\n",
      "[epoch: 20, batch:  1400] loss: 0.001\n",
      "\n",
      "Test set: Average loss: 1.2529, Accuracy: 0.8284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZANIUqvFWpxT"
   },
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "\n",
    "    _, test_loader = ImageProcessing()\n",
    "\n",
    "    dataiter = iter(test_loader)\n",
    "\n",
    "    # classes = ('plane', 'car', 'bird', 'cat',\n",
    "    #            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    classes = (\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "    'worm')\n",
    "    \n",
    "    for i in range(5):\n",
    "        inputs, targets = dataiter.next()\n",
    "\n",
    "        # print images\n",
    "        plt.imshow(imageConvert(make_grid(inputs)))\n",
    "        plt.show()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        print('GroundTruth: ', ' '.join('%5s' % classes[targets[j]] for j in range(10)))\n",
    "\n",
    "        net = EfficientNetB0(10).to(device)\n",
    "\n",
    "        PATH = './cifar_net.pth'\n",
    "\n",
    "        net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tM9Lch0XEM3l"
   },
   "outputs": [],
   "source": [
    "# evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "312yIrEetgq9"
   },
   "outputs": [],
   "source": [
    "# !rm -rf ./data/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9vV0DKJCwUNUmHCYkEsDh",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "EfficientNet_Appendix.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10dfc3fd6a964c3a9ec5838f7764e581": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1b4ff6f25e444235aeb6e5dc19098743": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c10c093c72e145209e099043f58f7755",
       "IPY_MODEL_28b5454f9e104c6c9bbb237378c54ee3"
      ],
      "layout": "IPY_MODEL_d44c043f8a1f43d0b985e4b12ffb9b03"
     }
    },
    "28b5454f9e104c6c9bbb237378c54ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_828bdfcd1fc34cb294e41516945780b0",
      "placeholder": "​",
      "style": "IPY_MODEL_fa485a2a64bc4e87a666aa3ab3a2bbdd",
      "value": " 170500096/? [00:20&lt;00:00, 95847721.15it/s]"
     }
    },
    "71a70c412cbe4eb0801877cbbd288c96": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "828bdfcd1fc34cb294e41516945780b0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c10c093c72e145209e099043f58f7755": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71a70c412cbe4eb0801877cbbd288c96",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10dfc3fd6a964c3a9ec5838f7764e581",
      "value": 1
     }
    },
    "d44c043f8a1f43d0b985e4b12ffb9b03": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa485a2a64bc4e87a666aa3ab3a2bbdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
